import io
import time
import streamlit as st
import numpy as np
import openai
import sys
import threading
import os
import PyPDF2
import tempfile
from gtts import gTTS
from dataclasses import dataclass

# --- Configuration de la page Streamlit ---
st.set_page_config(
    page_title="Simulateur d'Entretien d'Embauche IA",
    page_icon="ğŸ¤–",
    layout="wide"
)


# --- Dataclass pour les fichiers uploadÃ©s ---
@dataclass()
class DTO:  # For Data Transfer Object
    resume_content: str = None
    motivation_content: str = None
    job_offer_content: str = None


# --- Initialisation des variables de session ---
if "dto" not in st.session_state:
    st.session_state.dto = DTO()

if "api_key" not in st.session_state:
    st.session_state.api_key = "..."

if "llm_model" not in st.session_state:
    st.session_state.llm_model = "compound-beta-mini"

if "audio_activated" not in st.session_state:
    st.session_state.audio_activated = True

if "client" not in st.session_state:
    st.session_state.client = None

if "message_history" not in st.session_state:
    st.session_state.message_history = []

if "interview_started" not in st.session_state:
    st.session_state.interview_started = False

if "interview_ended" not in st.session_state:
    st.session_state.interview_ended = False

if "documents_ready" not in st.session_state:
    st.session_state.documents_ready = False


# --- Fonctions pour l'API et les traitements ---
def init_client():
    """Initialise le client API avec les paramÃ¨tres actuels."""
    try:
        st.session_state.client = openai.OpenAI(
            base_url="https://api.groq.com/openai/v1",
            api_key=st.session_state.api_key
        )
        return True
    except Exception as e:
        st.error(f"Erreur lors de l'initialisation du client API: {e}")
        return False


def extract_text_from_pdf(pdf_file):
    """Extrait le texte d'un fichier PDF."""
    reader = PyPDF2.PdfReader(pdf_file)
    text = ""
    for page_num in range(len(reader.pages)):
        page = reader.pages[page_num]
        text += page.extract_text()
    return text


def extract_text_from_file(file):
    """Extrait le texte d'un fichier (PDF ou TXT)."""
    if file is None:
        return ""

    file_extension = os.path.splitext(file.name)[1].lower()

    if file_extension == '.pdf':
        return extract_text_from_pdf(file)
    elif file_extension == '.txt':
        return file.getvalue().decode('utf-8')
    else:
        st.error(f"Format de fichier non pris en charge: {file_extension}")
        return ""


def tts(text):
    """Convertit le texte en audio et le joue."""
    if not st.session_state.audio_activated:
        return

    try:
        tts = gTTS(text, lang='fr')

        # CrÃ©er un fichier temporaire
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_file:
            tts.save(temp_file.name)

            # Jouer l'audio avec st.audio
            audio_file = open(temp_file.name, 'rb')
            audio_bytes = audio_file.read()
            st.audio(audio_bytes, format='audio/wav')
            audio_file.close()

        # Nettoyer le fichier temporaire
        os.unlink(temp_file.name)
    except Exception as e:
        st.error(f"Erreur lors de la synthÃ¨se vocale: {e}")


def ask_llm(message_history, max_tokens=150):
    """
    Envoie message_history Ã  l'API et affiche la rÃ©ponse en streaming.
    Retourne la rÃ©ponse complÃ¨te.
    """
    if st.session_state.client is None:
        if not init_client():
            return "Erreur de connexion Ã  l'API. Veuillez vÃ©rifier votre clÃ© API."

    try:
        stream = st.session_state.client.chat.completions.create(
            model=st.session_state.llm_model,
            messages=message_history,
            stream=True,
            max_tokens=max_tokens,
            temperature=0.5,
            top_p=0.9
        )

        # CrÃ©er un placeholder pour le streaming
        message_placeholder = st.empty()
        full_response = ""

        # Afficher le stream progressivement
        for chunk in stream:
            delta = chunk.choices[0].delta
            if delta.content:
                full_response += delta.content
                message_placeholder.markdown(f"**Recruteur:** {full_response}")

        return full_response

    except Exception as e:
        st.error(f"Erreur lors de la communication avec l'API: {e}")
        return f"Erreur: {str(e)}"


# --- Fonctions pour l'entretien ---
def prepare_documents(cv_file, job_offer_file, motivation_file):
    """PrÃ©pare les documents pour l'entretien."""
    with st.spinner("Traitement des documents..."):
        if cv_file and job_offer_file:
            st.session_state.dto.resume_content = extract_text_from_file(cv_file)
            st.session_state.dto.job_offer_content = extract_text_from_file(job_offer_file)

            if motivation_file:
                st.session_state.dto.motivation_content = extract_text_from_file(motivation_file)
            else:
                st.session_state.dto.motivation_content = "Non fournie"

            if init_client():
                st.session_state.documents_ready = True
                st.success("Documents chargÃ©s avec succÃ¨s! Vous pouvez maintenant dÃ©marrer l'entretien.")
                return True
            else:
                st.error("Erreur lors de l'initialisation du client API.")
                return False
        else:
            st.error("Veuillez charger au moins votre CV et l'offre d'emploi.")
            return False


def start_interview():
    """DÃ©marre l'entretien avec le recruteur IA."""
    if not st.session_state.documents_ready:
        st.error("Veuillez d'abord prÃ©parer les documents.")
        return

    st.session_state.message_history = [
        {"role": "system", "content": (
            "Vous Ãªtes un recruteur professionnel qui recrute un dÃ©veloppeur python spÃ©cialisÃ© en machine learning. "
            "Posez des questions d'entretien, une par une, et simulez un contexte d'entretien d'embauche. "
            "Attention Ã  ne pas trop parler, soyez concis et faites en sorte que l'interlocuteur parle ben plus que vous. "
            "Voici le CV du candidat :\n"
            f"{st.session_state.dto.resume_content}\n"
            "Voici la lettre de motivation du candidat :\n"
            f"{st.session_state.dto.motivation_content}\n"
            "Voici l'offre d'emploi Ã  laquelle il postule :\n"
            f"{st.session_state.dto.job_offer_content}\n"
            "Quand vous considÃ©rez que l'entretien est terminÃ©, envoyez uniquement 'Merci', cela terminera l'entretien."
        )}
    ]

    st.session_state.interview_started = True
    st.session_state.interview_ended = False

    # PremiÃ¨re question du recruteur
    st.markdown("### L'entretien commence")
    st.session_state.message_history.append({"role": "user", "content": "Bonjour"})
    st.markdown(st.session_state.message_history)
    recruteur_reply = ask_llm(st.session_state.message_history)
    st.markdown(recruteur_reply)
    st.session_state.message_history.append({"role": "assistant", "content": recruteur_reply})

    if st.session_state.audio_activated:
        tts(recruteur_reply)


def submit_response():
    """Traite la rÃ©ponse du candidat et gÃ©nÃ¨re la rÃ©ponse du recruteur."""
    user_input = st.session_state.user_input
    if not user_input.strip():
        return

    # Afficher la rÃ©ponse de l'utilisateur
    st.markdown(f"**Vous:** {user_input}")

    # Si la rÃ©ponse est 'merci' ou 'exit', on demande un feedback automatiquement
    if user_input.lower() in {"merci", "exit"}:
        st.session_state.message_history.append({"role": "user",
                                                 "content": "L'entretien est terminÃ©, fais moi un retour sur la maniÃ¨re dont Ã§a s'est passÃ© et donne moi des conseils pour mieux performer la prochaine fois, Ã©ventuellement des modifications Ã  apporter Ã  mon CV ou ma lettre de motivation."})
    else:
        st.session_state.message_history.append({"role": "user", "content": user_input})

    # Le recruteur Ã©crit sa rÃ©ponse selon l'historique de conversation
    recruteur_reply = ask_llm(st.session_state.message_history)

    # Si le recruteur dÃ©cide que l'interview est terminÃ©, il envoie merci
    if recruteur_reply.lower() == "merci" or len(st.session_state.message_history) >= 10:
        st.session_state.message_history.append({"role": "assistant", "content": "Merci, l'entretien est terminÃ©."})
        st.session_state.message_history.append({"role": "user",
                                                 "content": "L'entretien est terminÃ©, fais moi un retour sur la maniÃ¨re dont Ã§a s'est passÃ© et donne moi des conseils pour mieux performer la prochaine fois, Ã©ventuellement des modifications Ã  apporter Ã  mon CV ou ma lettre de motivation."})

        feedback = ask_llm(st.session_state.message_history, max_tokens=500)
        st.session_state.message_history.append({"role": "assistant", "content": feedback})

        if st.session_state.audio_activated:
            tts(feedback)

        st.session_state.interview_ended = True
    else:
        st.session_state.message_history.append({"role": "assistant", "content": recruteur_reply})

        if st.session_state.audio_activated:
            tts(recruteur_reply)

    # Vider le champ de saisie
    st.session_state.user_input = ""


# --- Interface principale ---
st.title("ğŸ¤– Simulateur d'Entretien d'Embauche IA")

# Barre latÃ©rale pour les configurations
with st.sidebar:
    st.header("Configuration")

    st.session_state.api_key = st.text_input("ClÃ© API Groq", value=st.session_state.api_key, type="password")
    st.session_state.llm_model = st.selectbox(
        "ModÃ¨le LLM",
        ["compound-beta-mini", "mistral-saba-24b", "llama-3.3-70b-versatile"],
        index=0
    )
    st.session_state.audio_activated = st.checkbox("Activer l'audio", value=st.session_state.audio_activated)

    # Upload des fichiers
    st.header("Documents")
    cv_file = st.file_uploader("Chargez votre CV (PDF ou TXT)", type=['pdf', 'txt'])
    job_offer_file = st.file_uploader("Chargez l'offre d'emploi (PDF ou TXT)", type=['pdf', 'txt'])
    motivation_file = st.file_uploader("Chargez votre lettre de motivation (facultatif) (PDF ou TXT)",
                                       type=['pdf', 'txt'])

    if st.button("PrÃ©parer l'entretien"):
        prepare_documents(cv_file, job_offer_file, motivation_file)

# Section principale - Affichage conditionnel
if not st.session_state.interview_started:
    st.info("ğŸ‘ˆ Configurez votre entretien dans le panneau de gauche.")

    # Bouton pour dÃ©marrer l'entretien uniquement si les documents sont prÃªts
    if st.session_state.documents_ready:
        if st.button("ğŸš€ DÃ©marrer l'entretien"):
            start_interview()

elif st.session_state.interview_ended:
    st.success("âœ… L'entretien est terminÃ©!")

    # Afficher le feedback final
    for message in st.session_state.message_history:
        if message["role"] == "assistant" and st.session_state.message_history[-1]["content"] == message["content"]:
            st.markdown("### Feedback du recruteur")
            st.markdown(message["content"])

    if st.button("ğŸ”„ Recommencer un nouvel entretien"):
        st.session_state.interview_started = False
        st.session_state.interview_ended = False
        st.session_state.documents_ready = False
        st.experimental_rerun()

else:
    # Afficher l'historique des messages pendant l'entretien
    for message in st.session_state.message_history:
        if message["role"] == "user" and message[
            "content"] != "L'entretien est terminÃ©, fais moi un retour sur la maniÃ¨re dont Ã§a s'est passÃ© et donne moi des conseils pour mieux performer la prochaine fois, Ã©ventuellement des modifications Ã  apporter Ã  mon CV ou ma lettre de motivation.":
            st.markdown(f"**Vous:** {message['content']}")
        elif message["role"] == "assistant":
            st.markdown(f"**Recruteur:** {message['content']}")

    # Zone de saisie pour la rÃ©ponse du candidat
    st.text_input("Votre rÃ©ponse:", key="user_input", on_change=submit_response)